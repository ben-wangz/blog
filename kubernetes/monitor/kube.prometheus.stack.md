# kube-prometheus-stack

## main usage

* collect metrics which show the status of nodes in k8s cluster
* collect metrics which show the status of k8s cluster
* collect metrics generated by pods in k8s
* send metrics to prometheus and visualized by grafana in real time

## conceptions

* [official docs](https://github.com/prometheus-operator/kube-prometheus-stack)
* [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack)
  is a helm chart for [kube-prometheus](https://github.com/prometheus-operator/kube-prometheus)
* kube-prometheus is a package contains
    + The [Prometheus Operator](https://github.com/prometheus-operator/prometheus-operator)
    + Highly available [Prometheus](https://prometheus.io/)
    + Highly available [Alertmanager](https://github.com/prometheus/alertmanager)
    + [Prometheus node-exporter](https://github.com/prometheus/node_exporter)
    + [Prometheus Adapter for Kubernetes Metrics APIs](https://github.com/DirectXMan12/k8s-prometheus-adapter)
    + [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics)
    + [Grafana](https://grafana.com/)
* more detailed usage documents for `prometheus-operator`:
  [user-guides of prometheus-operator](https://github.com/prometheus-operator/prometheus-operator/tree/main/Documentation/user-guides)

## purpose

* prepare a kind cluster with basic components(one master and three workers)
* setup kube prometheus stack
* create prometheus custom resources
* check metrics of nodes in k8s cluster in real time
* check metrics of k8s cluster in real time
* test with metrics generated by mysql service in real time

## installation

1. [prepare a kind cluster with basic components](../basic/kind.cluster.md)
    * modify `kind.cluster.yaml` to [kind.cluster.with.3.workers.yaml](../resources/kind.cluster.with.3.workers.yaml.md)
    * add hosts info to every worker node(master node has already been added)
        + ```shell
          for NODE in "kind-worker" "kind-worker2" "kind-worker3"
          do
              docker exec $NODE bash -c 'echo 172.17.0.1 docker.registry.local >> /etc/hosts' \
                  && docker exec $NODE bash -c 'echo 172.17.0.1 insecure.docker.registry.local >> /etc/hosts' \
                  && docker exec $NODE bash -c 'echo 172.17.0.1 chart.museum.local >> /etc/hosts'
          done
          ```
2. download and load images to qemu machine(run command at the host of qemu machine)
    * run scripts
      in [download.and.load.function.sh](../resources/create.qemu.machine.for.kind/download.and.load.function.sh.md) to
      load function `download_and_load`
    * ```shell
      TOPIC_DIRECTORY="kube.prometheus.stack.monitor"
      BASE_URL="https://resource.geekcity.tech/kubernetes/docker-images/x86_64"
      download_and_load $TOPIC_DIRECTORY $BASE_URL \
          "docker.io_quay.io_prometheus_alertmanager_v0.23.0.dim" \
          "docker.io_grafana_grafana_8.3.5.dim" \
          "docker.io_bats_bats_v1.4.1.dim" \
          "docker.io_curlimages_curl_7.73.0.dim" \
          "docker.io_busybox_1.31.1.dim" \
          "docker.io_quay.io_kiwigrid_k8s-sidecar_1.15.1.dim" \
          "docker.io_grafana_grafana-image-renderer_3.4.0.dim" \
          "docker.io_k8s.gcr.io_kube-state-metrics_kube-state-metrics_v2.3.0.dim" \
          "docker.io_quay.io_prometheus_node-exporter_v1.3.1.dim" \
          "docker.io_k8s.gcr.io_ingress-nginx_kube-webhook-certgen_v1.0.dim" \
          "docker.io_quay.io_prometheus-operator_prometheus-operator_v0.54.0.dim" \
          "docker.io_quay.io_prometheus-operator_prometheus-config-reloader_v0.54.0.dim" \
          "docker.io_quay.io_thanos_thanos_v0.24.0.dim" \
          "docker.io_quay.io_prometheus_prometheus_v2.33.1.dim"
      ```
3. configure self-signed issuer
    * `self-signed` issuer
        + prepare [self.signed.and.ca.issuer.yaml](../basic/resources/cert.manager/self.signed.and.ca.issuer.yaml.md)
        + ```shell
          kubectl get namespace monitor > /dev/null 2>&1 || kubectl create namespace monitor \
              && kubectl -n monitor apply -f self.signed.and.ca.issuer.yaml
          ```
4. install kube prometheus stack
    * prepare [kube.prometheus.stack.values.yaml](resources/kube.prometheus.stack/kube.prometheus.stack.values.yaml.md)
    * prepare images
        + run scripts in [load.image.function.sh](../resources/load.image.function.sh.md) to load function `load_image`
        + ```shell
          load_image "docker.registry.local:443" \
              "docker.io/quay.io/prometheus/alertmanager:v0.23.0" \
              "docker.io/grafana/grafana:8.3.5" \
              "docker.io/bats/bats:v1.4.1" \
              "docker.io/curlimages/curl:7.73.0" \
              "docker.io/busybox:1.31.1" \
              "docker.io/quay.io/kiwigrid/k8s-sidecar:1.15.1" \
              "docker.io/grafana/grafana-image-renderer:3.4.0" \
              "docker.io/k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.3.0" \
              "docker.io/quay.io/prometheus/node-exporter:v1.3.1" \
              "docker.io/k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.0" \
              "docker.io/quay.io/prometheus-operator/prometheus-operator:v0.54.0" \
              "docker.io/quay.io/prometheus-operator/prometheus-config-reloader:v0.54.0" \
              "docker.io/quay.io/thanos/thanos:v0.24.0" \
              "docker.io/quay.io/prometheus/prometheus:v2.33.1"
          ```
    * install by helm
        + ```shell
          # NOTE: kind start etcd on port 2381 instead of 2379
          # NOTE: for kind, x509 certificate is valid for 127.0.0.1, but not valid for the $REAL_IP
          helm install \
              --create-namespace --namespace monitor \
              my-kube-prometheus-stack \
              https://resource.geekcity.tech/kubernetes/charts/https/prometheus-community.github.io/helm-charts/kube-prometheus-stack-32.2.1.tgz \
              --values kube.prometheus.stack.values.yaml \
              --set kubeEtcd.service.targetPort=2381 \
              --set kubeScheduler.serviceMonitor.insecureSkipVerify=true \
              --atomic
          ```

## test

1. visit `https://grafana.local`
    * extract username and password
        + ```shell
          kubectl -n monitor get secret my-kube-prometheus-stack-grafana -o jsonpath="{.data.admin-user}" \
              | base64 --decode \
              && echo
          kubectl -n monitor get secret my-kube-prometheus-stack-grafana -o jsonpath="{.data.admin-password}" \
              | base64 --decode \
              && echo
          ```
    * check `Node Exporter/*` to figure out the status of nodes in k8s cluster
    * check `Kubernetes/*` to figure out the status of k8s cluster
2. install `mariadb` with metric generating feature
    * prepare [log.generator.yaml](resources/elk.stack/log.generator.yaml.md)
    * prepare images
        + run scripts in [load.image.function.sh](../resources/load.image.function.sh.md) to load function `load_image`
        + ```shell
          load_image "docker.registry.local:443" \
              "docker.io/febbweiss/java-log-generator:latest"
          ```
    * apply to k8s cluster
        + ```shell
          kubectl get namespace test > /dev/null 2>&1 || kubectl create namespace test \
              && kubectl -n test apply -f log.generator.yaml
          ```
3. visit kibana via website
    * add hosts info
        + ```shell
          echo "$IP kibana.local" >> /etc/hosts
          ```
    * visit `https://kibana.local/app/management/kibana/objects`
    * import [k8s-logs-dashboard.json](resources/elk.stack/k8s-logs-dashboard.ndjson.md)
4. filter with KQL
    + ```KQL
      kubernetes.labels.app : log-generator and message : *com.github.vspiewak.loggenerator.SearchRequest*
      ```

## uninstallation

1. delete `log-generator`
    + ```shell
      kubectl get namespace test > /dev/null 2>&1 || kubectl create namespace test \
          && kubectl -n test apply -f log.generator.yaml
     ```
4. uninstall `kube-prometheus-stack`
    * ```shell
      helm -n monitor uninstall my-kube-prometheus-stack
      ```
